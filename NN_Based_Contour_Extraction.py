# -*- coding: utf-8 -*-
"""united2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xgt7V3OKnOJDkuUOEAYKLf3zDQ1mwozG
"""

# from google.colab import drive
# drive.mount('/content/drive')

#resize for fisrt nn
import PIL
import os
import os.path
from PIL import Image
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
from PIL import Image, ImageFilter


def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def dice_loss(y_true, y_pred):
    smooth = 1.
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    y_true_f=tf.cast(y_true_f, tf.float32)
    y_pred_f=tf.cast(y_pred_f, tf.float32)
    intersection = y_true_f * y_pred_f
    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
    return 1. - score

def bce_dice_loss(y_true, y_pred):
    y_true=tf.cast(y_true, tf.float32)
    y_pred=tf.cast(y_pred, tf.float32)
    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)

f = r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\pic'

#prediction of first(femur) nn and save the 128*128 result
model_path=  r'E:\Project\Codes\Contour Extraction - Nural Network based method\bestmodelb8'
#Load previously saved model
from keras.models import load_model
model = tf.keras.models.load_model(model_path, custom_objects = {"dice_coef": dice_coef , "bce_dice_loss": bce_dice_loss})
import os
names='1.png'
print(len(names))

seed=24
batch_size= 1
n_classes=2

from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
#Define a function to perform additional preprocessing after datagen.
#For example, scale images, convert masks to categorical, etc. 
def preprocess_data(img, mask, num_class):
    #Scale images
    img = img / 255. #This can be done in ImageDataGenerator but showing it outside as an example
    #Convert mask to one-hot
    labelencoder = LabelEncoder()
    n, h, w, c = mask.shape  
    mask = mask.reshape(-1,1)
    mask = labelencoder.fit_transform(mask)
    mask = mask.reshape(n, h, w, c)
    mask = to_categorical(mask, num_class)
      
    return (img, mask)

#Define the generator.
#We are not doing any rotation or zoom to make sure mask values are not interpolated.
#It is important to keep pixel values in mask as 0, 1, 2, 3, .....
from tensorflow.keras.preprocessing.image import ImageDataGenerator
def trainGenerator(train_img_path, train_mask_path, num_class):
    
    img_data_gen_args = dict(horizontal_flip=False,
                      vertical_flip=False,
                      fill_mode='reflect')
    
    image_datagen = ImageDataGenerator(**img_data_gen_args)
    mask_datagen = ImageDataGenerator(**img_data_gen_args)
    
    image_generator = image_datagen.flow_from_directory(
        train_img_path,
        class_mode = None,
        color_mode = 'grayscale',
        target_size=(512,512),
        batch_size = batch_size,
        seed = seed)
    
    mask_generator = mask_datagen.flow_from_directory(
        train_mask_path,
        class_mode = None,
        color_mode = 'grayscale',
        target_size=(512,512),
        batch_size = batch_size,
        seed = seed)
    
    train_generator = zip(image_generator, mask_generator)
    
    for (img, mask) in train_generator:
        img, mask = preprocess_data(img, mask, num_class)
        yield (img, mask)
        
test_img_path = r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\femur\val_images'
test_mask_path = r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\femur\val_masks'
test_img_gen = trainGenerator(test_img_path, test_mask_path, num_class=2)
test_image_batch, test_mask_batch = test_img_gen.__next__()

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
print('len(names):', 1)
for i in range(1):
  test_img_number = i
  print(test_image_batch.shape)
  test_img = test_image_batch[test_img_number]
  # test_img = test_image_batch[i]
  test_img_norm=test_img[:,:,0][:,:,None]
  ground_truth=test_mask_batch[test_img_number]
  ground_truth = np.argmax(ground_truth, axis=2)
  test_img_input=np.expand_dims(test_img_norm, 0)
  prediction = (model.predict(test_img_input))
  predicted_img= np.argmax(prediction, axis=3)[0,:,:]

  #imageio.imwrite('/content/drive/MyDrive/data0/predicted/{}'.format(names[i],predicted_img), predicted_img) 

  im = Image.fromarray((predicted_img * 255).astype(np.uint8))
  im.save(r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\result1\1.png')

import matplotlib.pyplot as plt


# Resizing back
test_img_path = r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\femur\val_images\val\1.png'
origin_img = cv2.imread(test_img_path)
origin_shape = origin_img.shape[0:2]
origin_shape = np.array([origin_shape[1],origin_shape[0]])
output_mask_path = r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\result1'


for file in os.listdir(output_mask_path):
    f_img = output_mask_path+"/"+file
    g_img = output_mask_path+"/"+"resized_"+file
    img = Image.open(f_img)
    img = img.resize(origin_shape)
    img.save(g_img)

# output_mask = cv2.imread(r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\result1\resized_1.png')
mask_smoothed = Image.open(r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\result1\resized_1.png')
mask_smoothed = mask_smoothed.filter(ImageFilter.ModeFilter(size=19))
mask_smoothed = mask_smoothed.filter(ImageFilter.ModeFilter(size=19))
mask_smoothed.save(r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\result1\mask_smoothed.png')

mask_smoothed = cv2.imread(r'E:\Project\Codes\Contour Extraction - Nural Network based method\testdata\result1\mask_smoothed.png')
output_img = cv2.bitwise_and(origin_img, mask_smoothed)
cv2.imwrite(r'E:\Project\Codes\Contour Extraction - Nural Network based method\Output\output.png', output_img)